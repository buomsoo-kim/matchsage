{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87aa524b-e382-418f-a656-3167fba8688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from eval import *\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4240d0-79c9-40aa-bcec-82569da3e67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d800a3debd8d4239b490ac8749ca9317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/rkim0927/Python/Data/VB/dating_suggestions.csv\")\n",
    "\n",
    "test_period_start, test_period_end = '2022-02-01', '2022-02-15'\n",
    "train_interaction = data[(data['created_at'] > '2021-11-30') & (data['created_at'] < test_period_start)]\n",
    "test_interaction = data[(data['created_at'] > test_period_start) & (data['created_at'] < test_period_end)]\n",
    "\n",
    "unique_users = list(set(pd.concat([train_interaction[\"source_id\"], train_interaction[\"user_id\"]])))\n",
    "test_interaction = test_interaction[(test_interaction[\"user_id\"].isin(unique_users)) & (test_interaction[\"source_id\"].isin(unique_users))]\n",
    "print(len(unique_users))\n",
    "\n",
    "user_to_idx, idx_to_user = {}, {}\n",
    "for i in tqdm(range(len(unique_users))):\n",
    "  user_to_idx[unique_users[i]] = i\n",
    "  idx_to_user[i] = unique_users[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4050383-8371-48a4-a508-4878a9f0e132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86317519454549b4b5bc71abe503ca58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_src, embeddings_dst = pd.read_csv('/Users/rkim0927/Python/Data/VB/Embeddings/embeddings_user_matchsage.csv'), pd.read_csv('/Users/rkim0927/Python/Data/VB/Embeddings/embeddings_item_matchsage.csv')\n",
    "# embeddings_src, embeddings_dst = pd.DataFrame(embeddings_src, index = [x[1] for x in idx_to_user.items()]), pd.DataFrame(embeddings_dst, index = [x[1] for x in idx_to_user.items()])\n",
    "\n",
    "embeddings_src.set_index(\"Unnamed: 0\", drop = True, inplace = True)\n",
    "embeddings_dst.set_index(\"Unnamed: 0\", drop = True, inplace = True)\n",
    "\n",
    "src_to_embedding, dst_to_embedding = dict(), dict()\n",
    "\n",
    "for i in tqdm(range(len(embeddings_src))):\n",
    "  src_to_embedding[embeddings_src.index[i]] = embeddings_src.iloc[i].values\n",
    "  dst_to_embedding[embeddings_dst.index[i]] = embeddings_dst.iloc[i].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31e5c984-6256-4ce6-b45b-c92038a4c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDataset(Dataset):\n",
    "  def __init__(self, X1, X2, Y):\n",
    "    self.X1, self.X2 = X1, X2\n",
    "    self.Y = Y\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    return self.X1[idx], self.X2[idx],self.Y[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X1)\n",
    "\n",
    "class NCF(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_size, dropout, classify):\n",
    "    super(NCF, self).__init__()\n",
    "    self.classify = classify\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.bn = nn.BatchNorm1d(hidden_size)\n",
    "    self.dense_1 = nn.Linear(input_dim, hidden_size)\n",
    "    self.dense_2 = nn.Linear(input_dim, hidden_size)\n",
    "    self.dense =  nn.Linear(hidden_size*2, hidden_size)\n",
    "    self.dense_out = nn.Linear(hidden_size, 1)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x1, x2):\n",
    "    x1, x2 = self.relu(self.dense_1(x1)), self.relu(self.dense_2(x2))\n",
    "    x = torch.cat((x1, x2), axis = 1)\n",
    "    x = self.relu(self.dense(x))\n",
    "    x = self.dense_out(x)\n",
    "    if self.classify:\n",
    "      x = self.sigmoid(x)\n",
    "    return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "823a2030-354f-434c-a659-660c85e7d674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,) (1000000,) (1000000,) (160678,) (160678,) (160678,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(777)\n",
    "num_train = 1000000\n",
    "\n",
    "\n",
    "idx = np.random.choice(np.arange(len(train_interaction)), 1000000, replace=False)\n",
    "train_data = train_interaction.iloc[idx]\n",
    "\n",
    "X_train_user = train_data[\"user_id\"].map(src_to_embedding).values\n",
    "X_train_item = train_data[\"source_id\"].map(dst_to_embedding).values\n",
    "y_train =train_data[\"accepted\"].values\n",
    "\n",
    "X_test_user =  test_interaction[\"user_id\"].map(src_to_embedding).values\n",
    "X_test_item = test_interaction[\"source_id\"].map(dst_to_embedding).values\n",
    "y_test = test_interaction[\"accepted\"].values\n",
    "\n",
    "print(X_train_user.shape, X_train_item.shape, y_train.shape, X_test_user.shape, X_test_item.shape, y_test.shape )\n",
    "\n",
    "trainData = MLPDataset(X_train_user, X_train_item, y_train)\n",
    "testData = MLPDataset(X_test_user, X_test_item, y_test)\n",
    "trainLoader = DataLoader(trainData, batch_size = 256, shuffle = True)\n",
    "testLoader = DataLoader(testData, batch_size = 256, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "905598bf-fdc0-42d9-abbf-567bcc8f9d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.38113\n",
      "0.8192283916312013 0.478293804256633\n",
      "Epoch: 2, Loss: 0.38551\n",
      "0.8242441631005877 0.48514981152247283\n",
      "Epoch: 3, Loss: 0.27745\n",
      "0.823623284896424 0.4843952971411064\n",
      "Epoch: 4, Loss: 0.37157\n",
      "0.8242687319977 0.4885144039668089\n",
      "Epoch: 5, Loss: 0.40478\n",
      "0.8254456622696548 0.4907497835746387\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 100\n",
    "EMBEDDING_DIM = len(X_train_user[0])\n",
    "DROPOUT = .5\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_built() else \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "mlp = NCF(EMBEDDING_DIM, HIDDEN_SIZE, DROPOUT, True).to(device)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=LEARNING_RATE)  \n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "roauc, prauc = [], []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  for i, (x1, x2, y) in enumerate(trainLoader):\n",
    "    x1, x2, y = x1.float().to(device), x2.float().to(device),y.float().to(device)\n",
    "    \n",
    "    outputs = mlp(x1, x2)\n",
    "    loss = criterion(outputs, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  \n",
    "  print(\"Epoch: {}, Loss: {:.5f}\".format(epoch + 1, loss.item()))\n",
    "\n",
    "  y_prob = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for x1, x2, y in testLoader:\n",
    "      x1, x2, y = x1.float().to(device), x2.float().to(device),y.float().to(device)\n",
    "\n",
    "      outputs = mlp(x1, x2)\n",
    "      y_prob += list(outputs.cpu().numpy())\n",
    "  \n",
    "  r, p = roc_auc_score(y_test, y_prob), average_precision_score(y_test, y_prob)\n",
    "  print(r, p)\n",
    "  roauc.append(r)\n",
    "  prauc.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c66df-4478-482b-89f6-a6e3ec259bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
